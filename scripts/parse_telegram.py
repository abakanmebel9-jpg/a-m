import requests
import json
import os
import hashlib
from datetime import datetime
from pathlib import Path
import re
import sys
import time

class SimpleTelegramParser:
    def __init__(self, channel_name, max_posts=1000):
        self.channel_name = channel_name
        self.max_posts = max_posts
        self.base_url = f"https://t.me/s/{channel_name}"
        self.data_dir = Path("data")
        self.posts_dir = self.data_dir / "posts"
        self.setup_dirs()
        
    def setup_dirs(self):
        self.posts_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
    def fetch_channel(self):
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        try:
            response = requests.get(self.base_url, headers=headers, timeout=30)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"Error fetching Telegram: {e}")
            return None
    
    def parse_messages(self, html):
        posts = []
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É Telegram
        # –ò—â–µ–º ID —Å–æ–æ–±—â–µ–Ω–∏–π
        message_pattern = r'data-post="([^"]+)"'
        matches = re.findall(message_pattern, html)
        
        for i, post_id_full in enumerate(matches[:self.max_posts]):
            try:
                post_id = post_id_full.split('/')[-1] if '/' in post_id_full else post_id_full
                
                # –ò—â–µ–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
                text_pattern = rf'data-post="{re.escape(post_id_full)}"[^>]*>.*?<div class="tgme_widget_message_text[^>]*>(.*?)</div>'
                text_match = re.search(text_pattern, html, re.DOTALL)
                text = text_match.group(1).strip() if text_match else f"–°–æ–æ–±—â–µ–Ω–∏–µ #{i+1}"
                
                # –û—á–∏—â–∞–µ–º HTML –∏–∑ —Ç–µ–∫—Å—Ç–∞
                text = re.sub(r'<[^>]+>', '', text)
                
                # –ò—â–µ–º –¥–∞—Ç—É
                date_pattern = rf'data-post="{re.escape(post_id_full)}"[^>]*>.*?<time[^>]*datetime="([^"]+)"'
                date_match = re.search(date_pattern, html, re.DOTALL)
                date_str = date_match.group(1) if date_match else datetime.now().isoformat()
                
                post = {
                    'id': post_id,
                    'text': text,
                    'date': date_str,
                    'timestamp': int(datetime.now().timestamp()) - i*60,
                    'hashtags': re.findall(r'#(\w+)', text),
                    'word_count': len(text.split()),
                    'source': 'telegram'
                }
                posts.append(post)
            except Exception as e:
                print(f"Error parsing message {i}: {e}")
                continue
                
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, —Å–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
        if not posts:
            print("No posts found, creating demo data")
            posts = [{
                'id': f'demo_{i}',
                'text': f'üöÄ –ü—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞ #{i+1}. –°–∏—Å—Ç–µ–º–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞! –ù–∞—Å—Ç–æ—è—â–∏–µ –ø–æ—Å—Ç—ã –ø–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞. –ö–∞–Ω–∞–ª: @abakan_mebel',
                'date': datetime.now().isoformat(),
                'timestamp': int(datetime.now().timestamp()) - i*3600,
                'hashtags': ['—Ç–µ—Å—Ç', '–¥–µ–º–æ'],
                'word_count': 20,
                'source': 'demo'
            } for i in range(10)]
        
        return posts
        
    def save_posts(self, posts):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã (–¥–æ 1000)
        all_posts = sorted(posts, key=lambda x: x.get('timestamp', 0), reverse=True)[:self.max_posts]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
        posts_file = self.data_dir / "posts.json"
        with open(posts_file, 'w', encoding='utf-8') as f:
            json.dump({
                'channel': self.channel_name,
                'updated_at': datetime.now().isoformat(),
                'post_count': len(all_posts),
                'max_posts': self.max_posts,
                'posts': all_posts
            }, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = self.data_dir / "stats.json"
        hashtags_count = {}
        for post in all_posts:
            for tag in post.get('hashtags', []):
                hashtags_count[tag] = hashtags_count.get(tag, 0) + 1
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump({
                'total_posts': len(all_posts),
                'total_words': sum(p.get('word_count', 0) for p in all_posts),
                'hashtags': dict(sorted(hashtags_count.items(), key=lambda x: x[1], reverse=True)[:10]),
                'last_updated': datetime.now().isoformat(),
                'channel': self.channel_name
            }, f, ensure_ascii=False, indent=2)
                
        return len(all_posts)
            
    def run(self):
        print(f"–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {self.channel_name}")
        html = self.fetch_channel()
        
        if not html:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Telegram, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ")
            posts = [{
                'id': f'demo_{i}',
                'text': f'–ü—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞ #{i+1}. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å @abakan_mebel',
                'date': datetime.now().isoformat(),
                'timestamp': int(datetime.now().timestamp()) - i*3600,
                'hashtags': ['—Ç–µ—Å—Ç'],
                'word_count': 15,
                'source': 'demo'
            } for i in range(5)]
        else:
            posts = self.parse_messages(html)
                
        saved = self.save_posts(posts)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ—Å—Ç–æ–≤: {saved}")
        return saved

if __name__ == "__main__":
    channel = os.getenv('CHANNEL', 'abakan_mebel')
    max_posts = int(os.getenv('MAX_POSTS', '1000'))
    parser = SimpleTelegramParser(channel, max_posts)
    parser.run()
